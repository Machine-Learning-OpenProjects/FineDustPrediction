{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv = 'MonthlyAverageAirPollutionInSeoul.csv'\n",
    "\n",
    "seoul_map = [ # 9 by 8 matrix, 25 borough\n",
    "    [0, 0, 0, 0, '도봉구', '노원구', 0, 0],\n",
    "    [0, 0, 0, '강북구', '강북구', '노원구', '노원구', 0],\n",
    "    [0, '은평구', '종로구', '성북구', '성북구', '성북구', '중랑구', 0],\n",
    "    [0, '은평구', '서대문구', '종로구', '종로구', '동대문구', '중랑구', 0],\n",
    "    [0, '은평구', '서대문구', '서대문구', '중구', '성동구', '광진구', '강동구'],\n",
    "    [0, '마포구', '마포구', '마포구', '용산구', '강남구', '송파구', '강동구'],\n",
    "    ['강서구', '강서구', '영등포구', '동작구', '서초구', '강남구', '송파구', 0],\n",
    "    [0, '양천구', '영등포구', '관악구', '서초구', '강남구', '송파구', 0],\n",
    "    [0, '구로구', '금천구', '관악구', '서초구', 0, 0, 0]\n",
    "]\n",
    "\n",
    "with open(csv) as f:\n",
    "    raw_data = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del_quote = raw_data.replace(\"\\\"\", '')\n",
    "data = list(map(lambda x: x.split(','), del_quote.split('\\n')))[1:]\n",
    "\n",
    "splitted = []\n",
    "\n",
    "ptr = 0\n",
    "for i in range(len(data) // 39):\n",
    "    splitted.append(data[ptr:ptr+39])\n",
    "    ptr += 39\n",
    "    \n",
    "## test case\n",
    "for date_list in splitted:\n",
    "    date = date_list[0][0]\n",
    "    for local in date_list:\n",
    "        if date != local[0]:\n",
    "            raise ValueError(date + ' is not same as ' + 'local[0]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def filter_borough(dic):\n",
    "    return dict(filter(lambda t: '구' in t[0], dic.items()))\n",
    "\n",
    "pms = dict(map(lambda x: (x[0][0], dict(map(lambda x: (x[1], x[6]), x))), splitted))\n",
    "pms_filtered = dict(filter(lambda x: '' not in x[1].values(), pms.items()))\n",
    "pms_filtered2 = dict(map(lambda x: (x[0], filter_borough(x[1])), pms_filtered.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dict2seoul(p):\n",
    "    return list(map(lambda t: list(map(lambda x: int(p[x]) if x != 0 else 0, t)), seoul_map))\n",
    "\n",
    "pms_mapped = dict(map(lambda p: (p[0], dict2seoul(p[1])), pms_filtered2.items()))\n",
    "pms_data = list(map(lambda x: x[1], sorted(pms_mapped.items())))\n",
    "pms_result = list(map(lambda x: list(map(lambda t: t[1], sorted(x[1].items()))), sorted(pms_filtered2.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(layer):\n",
    "    return tf.maximum(0.2*layer, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 9, 8, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w1 = tf.get_variable('w1', shape=[3, 3, 1, 32],\n",
    "                    initializer=tf.random_normal_initializer())\n",
    "w2 = tf.get_variable('w2', shape=[3, 3, 32, 64],\n",
    "                    initializer=tf.random_normal_initializer())\n",
    "w3 = tf.get_variable('w3', shape=[3, 3, 64, 128],\n",
    "                    initializer=tf.random_normal_initializer())\n",
    "\n",
    "l1 = tf.nn.conv2d(X, w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "l1 = tf.contrib.layers.batch_norm(leaky_relu(l1))\n",
    "\n",
    "l2 = tf.nn.conv2d(l1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "l2 = tf.contrib.layers.batch_norm(leaky_relu(l2))\n",
    "\n",
    "l3 = tf.nn.conv2d(l2, w3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "l3 = tf.contrib.layers.batch_norm(leaky_relu(l3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
